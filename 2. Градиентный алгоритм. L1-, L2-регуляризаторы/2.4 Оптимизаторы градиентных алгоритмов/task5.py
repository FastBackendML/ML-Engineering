import numpy as np
import matplotlib.pyplot as plt
import time

# логарифмическая функция потерь
def loss(w, x, y):
    M = np.dot(x, w) * y
    return np.log2(1 + np.exp(-M))


# производная логарифмической функции потерь по вектору w
def df(w, x, y):
    M = np.dot(x, w) * y
    return -(np.exp(-M) * x.T * y) / ((1 + np.exp(-M)) * np.log(2))


data_x = [(5.3, 2.3), (5.7, 2.5), (4.0, 1.0), (5.6, 2.4), (4.5, 1.5), (5.4, 2.3), (4.8, 1.8), (4.5, 1.5), (5.1, 1.5),
          (6.1, 2.3), (5.1, 1.9), (4.0, 1.2), (5.2, 2.0), (3.9, 1.4), (4.2, 1.2), (4.7, 1.5), (4.8, 1.8), (3.6, 1.3),
          (4.6, 1.4), (4.5, 1.7), (3.0, 1.1), (4.3, 1.3), (4.5, 1.3), (5.5, 2.1), (3.5, 1.0), (5.6, 2.2), (4.2, 1.5),
          (5.8, 1.8), (5.5, 1.8), (5.7, 2.3), (6.4, 2.0), (5.0, 1.7), (6.7, 2.0), (4.0, 1.3), (4.4, 1.4), (4.5, 1.5),
          (5.6, 2.4), (5.8, 1.6), (4.6, 1.3), (4.1, 1.3), (5.1, 2.3), (5.2, 2.3), (5.6, 1.4), (5.1, 1.8), (4.9, 1.5),
          (6.7, 2.2), (4.4, 1.3), (3.9, 1.1), (6.3, 1.8), (6.0, 1.8), (4.5, 1.6), (6.6, 2.1), (4.1, 1.3), (4.5, 1.5),
          (6.1, 2.5), (4.1, 1.0), (4.4, 1.2), (5.4, 2.1), (5.0, 1.5), (5.0, 2.0), (4.9, 1.5), (5.9, 2.1), (4.3, 1.3),
          (4.0, 1.3), (4.9, 2.0), (4.9, 1.8), (4.0, 1.3), (5.5, 1.8), (3.7, 1.0), (6.9, 2.3), (5.7, 2.1), (5.3, 1.9),
          (4.4, 1.4), (5.6, 1.8), (3.3, 1.0), (4.8, 1.8), (6.0, 2.5), (5.9, 2.3), (4.9, 1.8), (3.3, 1.0), (3.9, 1.2),
          (5.6, 2.1), (5.8, 2.2), (3.8, 1.1), (3.5, 1.0), (4.5, 1.5), (5.1, 1.9), (4.7, 1.4), (5.1, 1.6), (5.1, 2.0),
          (4.8, 1.4), (5.0, 1.9), (5.1, 2.4), (4.6, 1.5), (6.1, 1.9), (4.7, 1.6), (4.7, 1.4), (4.7, 1.2), (4.2, 1.3),
          (4.2, 1.3)]
data_y = [1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1,
          -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1,
          -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1,
          1, -1, -1, -1, -1, -1]

x_train = np.array([[1, x[0], x[1]] for x in data_x])
y_train = np.array(data_y)

n_train = len(x_train)  # размер обучающей выборки
w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты
nt = np.array([0.1, 0.05, 0.05])  # шаг обучения для каждого параметра w0, w1, w2
lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего
N = 200  # число итераций алгоритма SGD
batch_size = 10  # размер мини-батча (величина K = 10)

alpha = 0.7  # параметр для RMSProp
G = np.zeros(len(w))  # параметр для RMSProp
eps = 0.01  # параметр для RMSProp

Qe = sum(loss(w, x_train, y_train)) / n_train  # начальное значение среднего эмпирического риска
np.random.seed(0)  # генерация одинаковых последовательностей псевдослучайных чисел

Qe_values = []
K = 10
# здесь продолжайте программу
for n in range(N):
    k = np.random.randint(0, n_train - batch_size - 1)
    Xi = x_train[range(k, k + batch_size)]
    Yi = y_train[range(k, k + batch_size)]

    Qk = loss(w, Xi, Yi).mean()
    dQk = df(w, Xi, Yi).mean(1)

    G = alpha * G + (1 - alpha) * dQk**2
    w = w - nt * dQk / (np.sqrt(G) + eps)
    Qe = lm * Qk + (1 - lm) * Qe
    Qe_values.append(Qe)

M = np.dot(w, x_train.T) * y_train
Q = np.sum(M<0)/len(M)
# Построение графика изменения Qe
plt.figure(figsize=(12, 6))

# График ошибки (Qe)
plt.subplot(1, 2, 1)
plt.plot(Qe_values)
plt.xlabel('Итерация')
plt.ylabel('Средний эмпирический риск Qe')
plt.title('Изменение среднего эмпирического риска (Qe)')
plt.grid(True)

# График разделяющей прямой
plt.subplot(1, 2, 2)
plt.scatter(x_train[:, 1], x_train[:, 2], c=y_train, cmap='bwr', alpha=0.7, label='Обучающие данные')
x1_range = np.linspace(min(x_train[:, 1]), max(x_train[:, 1]), 100)
x2_range = (-w[0] - w[1] * x1_range) / w[2]  # Уравнение прямой
plt.plot(x1_range, x2_range, 'g--', label='Разделяющая прямая')

plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Разделяющая прямая')
plt.legend()

plt.tight_layout()
plt.show()

print(f"Точность модели: {Q:.4f}")
