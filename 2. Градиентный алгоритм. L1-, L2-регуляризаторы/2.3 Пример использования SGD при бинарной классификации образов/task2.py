import numpy as np
import matplotlib.pyplot as plt
import time

# экспоненциальная функция потерь
def loss(w, x, y):
    M = np.dot(w, x) * y
    return np.exp(-M)


# производная экспоненциальной функции потерь по вектору w
def df(w, x, y):
    M = np.dot(w, x) * y
    return -np.exp(-M) * x.T * y


data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6),
          (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3),
          (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8),
          (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3),
          (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3),
          (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5),
          (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9),
          (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5),
          (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2),
          (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5),
          (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5),
          (5.9, 1.8)]
data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1,
          -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1,
          1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1,
          -1, -1, -1, -1, 1]

x_train = np.array([[1, x[0], x[1]] for x in data_x])
y_train = np.array(data_y)

n_train = len(x_train)  # размер обучающей выборки
w = np.array([0.0, 0.0, 0.0])  # начальные весовые коэффициенты
nt = np.array([0.5, 0.01, 0.01])  # шаг обучения для каждого параметра w0, w1, w2
lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего
N = 500  # число итераций алгоритма SGD
batch_size = 10  # размер мини-батча (величина K = 10)

Qe = sum(loss(w, x_train[i], y_train[i]) for i in
         range(n_train)) / n_train  # начальное значение среднего эмпирического риска
np.random.seed(0)  # генерация одинаковых последовательностей псевдослучайных чисел
K = 10
plt.ion()
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
coords_scatter_x = x_train[y_train == 1]
coords_scatter_y = x_train[y_train == -1]
ax1.scatter(coords_scatter_x[:, 1], coords_scatter_x[:, 2], color='red', zorder=2)
ax1.scatter(coords_scatter_y[:, 1], coords_scatter_y[:, 2], color='blue', zorder=2)

coords_line_x = [min(x_train[:, 1]), max(x_train[:, 1])]  # Начальные координаты точек линии

coords_line_y = [0, 0]  # Начальные координаты точек линии

line_1, = ax1.plot(coords_line_x, coords_line_y, color='green', zorder=2, label='Разделяющая линия')

ax1.set_xlim(min(x_train[:, 1]) - 0.1, max(x_train[:, 1]) + 0.1)  # Установление пределов по шкале

ax1.set_ylim(min(x_train[:, 2]) - 0.1, max(x_train[:, 2]) + 0.1)  # Установление пределов по шкале

line_2, = ax2.plot([], [], color='red', label='Qe')  # Построение графика Qe

ax2.set_xlim(0, N)  # Установление пределов по шкале

ax2.set_ylim(0, 2)  # Установление пределов по шкале

Qe_values = []  # Значения Qe для построения графика

ax1.set_title('Построение разделяющей линии')  # Установка названия графика

ax2.set_title('Отображение изменений графика Qe')  # Установка названия графика

ax1.legend()  # Отображение легенды на графике

ax2.legend()  # Отображение легенды на графике

ax1.grid(zorder=1)  # Отображение сетки на графике

ax2.grid(zorder=1)  # Отображение сетки на графике

# здесь продолжайте программу
for n in range(N):
    k = np.random.randint(0, n_train - batch_size - 1)
    Xi = x_train[k: k + batch_size]
    Yi = y_train[k: k + batch_size]

    Qk = 0
    dLw = 0
    for i,k in enumerate(Yi):
        Qk += loss(w, Xi[i], k)
        dLw += df(w, Xi[i], k)

    dQk = dLw / K
    Qk = Qk / K
    w = w - nt * dQk
    Qe = lm * Qk + (1 - lm) * Qe
    Qe_values.append(Qe)
    coords_line_y = [(-w[1] * x - w[0]) / w[2] for x in coords_line_x]  # Задание новых координат линии
    line_1.set_ydata(coords_line_y)  # Установка новых координат линии (обновление существующих координат)

    line_2.set_data(range(len(Qe_values)),
                    Qe_values)  # Установка новых координат для графика Qe (обновление существующих координат)

    fig.canvas.draw()  # Перерисовывает текущую фигуру

    fig.canvas.flush_events()  # Очистка внутренних событий

    time.sleep(0.01)  # Установка задержки перед выполнением следующей операции

Q = sum([(x_train[i] @ w.T) * y_train[i] < 0 for i in range(n_train)]) / n_train
print(Q)
print(Qe)
print(w)
plt.ioff()
plt.show()
